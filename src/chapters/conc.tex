\chapter{Path Forward}
% The implementation of the most effective model for real-time semantic segmentation in our robot bin picking task has been a significant endeavor, combining theoretical knowledge from research literature with practical engineering principles. Throughout the project, we encountered several challenges and gained valuable insights, shaping our understanding of effective model development and deployment strategies.

\section{Pain Points}
One of the notable pain points encountered during the implementation process was the unpredictable nature of model performance during training. Despite following established methodologies and best practices, we observed instances where the trained models exhibited inconsistent results, sometimes performing better than expected, while other times yielding suboptimal outcomes. This variability underscored the inherent complexity of deep learning models and the sensitivity of their performance to various factors, such as hyperparameter tuning, data preprocessing, and random initialization.

Another challenge we faced was the integration of the ENet model with custom datasets. While the model architecture and implementation were well-documented, adapting it to work seamlessly with our specific dataset required careful consideration of data formats, preprocessing steps, and compatibility across different components of the pipeline. This process highlighted the importance of robust data handling and the need for modular, extensible implementations that can accommodate diverse data sources.

Additionally, we encountered issues related to computational resources and hardware limitations. Training deep learning models, especially for complex tasks like image segmentation, can be computationally intensive and often requires access to high-performance hardware accelerators. While leveraging Google Colab's GPU resources mitigated this challenge to some extent, we recognized the potential benefits of exploring more scalable and dedicated computing environments for larger-scale deployments.

\section{Upcoming}
Building upon the foundations established in this project, several avenues for future work and improvement have been identified and planned for the future weeks. It should be noted that as a subgroup our plan regarding the ENet implementation is already layed out in the relevant chapter, this section covers the overall goals of the project with our sub groups focus.
\subsection{Integration of Database Techniques 05/04/2024}
Exploring the integration of database techniques, such as those employed in the Segment Anything Model (SAM), into the ENet architecture could potentially enhance its performance and adaptability. By leveraging the strengths of both approaches, we aim to develop a more robust and versatile segmentation system.
\subsection{Utility Function Improvements 04/04/2024}
To streamline the training and evaluation processes, further enhancements to the utility functions within the ENet implementation are planned. These improvements will aim to improve reproducibility, facilitate hyperparameter tuning, and provide more comprehensive performance metrics and visualizations.
\subsection{Data Annotation and Preparation 07/04/2024}
Continuous efforts will be dedicated to annotating and preparing high-quality training and test data. This includes exploring semi-automated annotation techniques, crowdsourcing strategies within the group, and leveraging domain expertise to ensure accurate and diverse dataset representations.
% Literature Review and Model Integration: Ongoing literature reviews will be conducted to explore promising options for object detection convolutional neural networks (CNNs) and instance segmentation models. Integrating these advanced techniques with the ENet architecture, while preserving its computational efficiency advantages, is a key area of investigation.
\subsection{Modular Semantic Segmentation - Ongoing}
To enhance the versatility and adaptability of the system, efforts will be made to modularize the semantic segmentation component within the ENet pipeline. This modularization will allow for the seamless integration and evaluation of alternative semantic segmentation models, facilitating comparative analyses and informed decision-making based on performance and resource requirements.

\subsection{Instance Segmentation - 11/04/2024}
Integrate object identification models, such as Mask R-CNN or YOLACT, on top of the ENet-based semantic segmentation pipeline to create a comprehensive instance segmentation system. This involves enhancing the dataset diversity, exploring multi-task learning approaches, refining segmentation outputs with fusion techniques, optimizing for edge deployment, ensuring continuous training, and planning for real-world integration and deployment.

\subsection{Deterministic Environments and Reproducibility - Ongoing}
Exploring deterministic environments such as Nix or Docker will be a priority to ensure strict reproducibility of models and results across different platforms and computing environments. This will contribute to the overall robustness and reliability of the developed solutions.
\subsection{Edge Deployment and Docker Setup - TBD}
As the project progresses, a focus will be placed on streamlining the deployment process for running trained models on edge devices and embedded systems. This will involve establishing a Docker-based deployment setup, enabling efficient and consistent execution of the models in real-world scenarios.

By addressing these future directions, we aim to continuously improve the performance, flexibility, and real-world applicability of the ENet-based image segmentation system, contributing to the advancement of computer vision techniques and their practical applications across various domains.

\chapter*{References}

 [1] ajax0564, “E-NET image segmentation,” Kaggle, https://www.kaggle.com/code/ajax0564/e-net-image-segmentation (accessed Mar. 28, 2024).

  [2] A. Shamsian, "Image segmentation overview \& enet implementation," Medium,https://medium.com/@mista2311/image-segmentation-overview-enet-implementation-8394ff71cf26 (accessed Mar. 28, 2024).

  [3] Davidtvs, “Davidtvs/Pytorch-ENet: Pytorch implementation of enet,” GitHub,https://github.com/davidtvs/PyTorch-ENet?tab=readme-ov-file (accessed Mar. 28, 2024).

  [4] iArunava, “IARUNAVA/Enet-real-time-semantic-segmentation: Enet - a neural net architecture for real time semantic segmentation,” GitHub, https://github.com/iArunava/ENet-Real-Time-Semantic-Segmentation (accessed Mar. 28, 2024).

  [5] A. Paszke, A. Chaurasia, S. Kim, and E. Culurciello, “Enet: A deep neural network architecture for real-time semantic segmentation,” arXiv.org, https://arxiv.org/abs/1606.02147 (accessed Mar. 28, 2024).

  [6] Kulkarnikeerti, “Kulkarnikeerti/segnet-semantic-segmentation: Deep convolutional encoder-decoder network for image segmentation,” GitHub, https://github.com/kulkarnikeerti/SegNet-Semantic-Segmentation (accessed Mar. 28,2024).

  [7] V. Badrinarayanan, A. Kendall, and R. Cipolla, “SegNet: A deep convolutional encoder-decoder architecture for image segmentation,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 39, no. 12, pp. 2481-2495, Dec. 2017.doi:10.1109/tpami.2016.2644615